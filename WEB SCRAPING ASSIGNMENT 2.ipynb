{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\chaitali nakade\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\chaitali nakade\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "#install selenium\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all neccessory libreries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "libreries imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.1-  Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” \n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get url in web driver first\n",
    "url = 'https://www.naukri.com/'\n",
    "web_driver.get(url)\n",
    "#the url will open \n",
    "\n",
    "#inspect for Skill,Designations,Companies field\n",
    "job_search = web_driver.find_element_by_id('qsb-keyword-sugg')\n",
    "#this will write text on search bar\n",
    "job_search.send_keys('Data Analyst')\n",
    "\n",
    "#find element for job location\n",
    "search_location = web_driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_location.send_keys('Bangalore')\n",
    "\n",
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB TITLES</th>\n",
       "      <th>JOB LOCATION</th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst - Einstein Analytics</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Enquero</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - 0-2 years (6 month contract)</td>\n",
       "      <td>New Delhi, Gurgaon/Gurugram, Chennai, Bangalor...</td>\n",
       "      <td>NIUM INDIA PRIVATE LIMITED</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>CAREERLABS TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengal...</td>\n",
       "      <td>Nx-DT</td>\n",
       "      <td>10-16 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SQL Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Business Analyst- Data Science</td>\n",
       "      <td>Bangalore/Bengaluru(Whitefield)</td>\n",
       "      <td>Evalueserve.com Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business/Data Analyst - Colleague Experience &amp;...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Vmware</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Telstra India Pvt Ltd</td>\n",
       "      <td>7-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst (SQL+Predictive Analytics+ Python)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JOB TITLES  \\\n",
       "0           Senior Data Analyst - Einstein Analytics   \n",
       "1        Data Analyst - 0-2 years (6 month contract)   \n",
       "2                                       Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4                                Senior Data Analyst   \n",
       "5                                   SQL Data Analyst   \n",
       "6              Senior Business Analyst- Data Science   \n",
       "7  Business/Data Analyst - Colleague Experience &...   \n",
       "8                                Senior Data Analyst   \n",
       "9    Data Analyst (SQL+Predictive Analytics+ Python)   \n",
       "\n",
       "                                        JOB LOCATION  \\\n",
       "0        Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "1  New Delhi, Gurgaon/Gurugram, Chennai, Bangalor...   \n",
       "2            Bangalore/Bengaluru\\n(WFH during Covid)   \n",
       "3                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "4  Hyderabad/Secunderabad, Pune, Bangalore/Bengal...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                    Bangalore/Bengaluru(Whitefield)   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                              COMPANY NAME EXPERIENCE  \n",
       "0                                  Enquero    3-5 Yrs  \n",
       "1               NIUM INDIA PRIVATE LIMITED    0-2 Yrs  \n",
       "2  CAREERLABS TECHNOLOGIES PRIVATE LIMITED    0-3 Yrs  \n",
       "3           Tata Consultancy Services Ltd.    4-8 Yrs  \n",
       "4                                    Nx-DT  10-16 Yrs  \n",
       "5                                   NetApp    3-7 Yrs  \n",
       "6                 Evalueserve.com Pvt. Ltd    2-7 Yrs  \n",
       "7                                   Vmware    3-8 Yrs  \n",
       "8                    Telstra India Pvt Ltd    7-8 Yrs  \n",
       "9                             AVE-Promagne    1-3 Yrs  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the tag having job titles\n",
    "job_title = web_driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "job_titles = [] #empty list\n",
    "\n",
    "for i in job_title[0:10]:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "    \n",
    "#extract the tag having job location\n",
    "job_loc = web_driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "\n",
    "job_location = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for j in job_loc[0:10]:\n",
    "    job_location.append(j.text)\n",
    "\n",
    "    \n",
    "#extract the tag having company name\n",
    "company = web_driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "company_name = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having experience\n",
    "experience_req = web_driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "\n",
    "experience = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in experience_req[0:10]:\n",
    "    experience.append(i.text)\n",
    "\n",
    "# Make data frame of datanalyst job from naukari.com \n",
    "Data_Analyst = pd.DataFrame({})\n",
    "Data_Analyst['JOB TITLES']= job_titles\n",
    "Data_Analyst['JOB LOCATION'] = job_location\n",
    "Data_Analyst['COMPANY NAME'] = company_name \n",
    "Data_Analyst['EXPERIENCE'] = experience\n",
    "Data_Analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.2- Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter \n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get url in web driver first\n",
    "url = 'https://www.naukri.com/'\n",
    "web_driver.get(url)\n",
    "#the url will open \n",
    "\n",
    "#inspect for Skill,Designations,Companies field\n",
    "job_search = web_driver.find_element_by_id('qsb-keyword-sugg')\n",
    "#this will write text on search bar\n",
    "job_search.send_keys('Data Scientist')\n",
    "\n",
    "#find element for job location\n",
    "search_location = web_driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_location.send_keys('Bangalore')\n",
    "\n",
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having job titles\n",
    "job_title = web_driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "job_titles = [] #empty list\n",
    "\n",
    "for i in job_title[0:10]:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "    \n",
    "#extract the tag having job location\n",
    "job_loc = web_driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "\n",
    "job_location = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in job_loc[0:10]:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "    \n",
    "#extract the tag having company name\n",
    "company = web_driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "company_name = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having urls of all compaies\n",
    "url = web_driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_urls = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in url[0:10]:\n",
    "    job_urls.append(i.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = [] #Empty list\n",
    "for i in job_urls:\n",
    "    web_driver.get(i)\n",
    "    try:\n",
    "        job = web_driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "        job_description.append(job.text)\n",
    "    except:\n",
    "        job_description.append('--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(job_location),len(company_name),len(job_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB TITLES</th>\n",
       "      <th>JOB LOCATION</th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>JOB DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist- Senior Business Analyst/Lead A...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Evalueserve.com Pvt. Ltd</td>\n",
       "      <td>Job description\\nJob Description\\nUnderstand a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Data Scientist - Retail Industry</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior/ Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Superior Group</td>\n",
       "      <td>Job description\\nProvide advanced analytical c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>SMITHS DETECTION SYSTEMS PRIVATE LIMITED</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cognizer India Private Limited</td>\n",
       "      <td>Job description\\n\\nRoles and Responsibilities\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Zycus Infotech Pvt Ltd</td>\n",
       "      <td>Job description\\nZycus is looking for applican...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>TransOrg Solutions Services (P) Ltd.</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist / Tech Lead - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Job description\\nResponsibilities -\\nLead a te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist - KPO</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>TalentCo Search Pvt Ltd</td>\n",
       "      <td>Job description\\n- Ability to understand a pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JOB TITLES  \\\n",
       "0  Data Scientist- Senior Business Analyst/Lead A...   \n",
       "1              Lead Data Scientist - Retail Industry   \n",
       "2                        Senior/ Lead Data Scientist   \n",
       "3                 Data Scientist: Advanced Analytics   \n",
       "4                              Senior Data Scientist   \n",
       "5                              Senior Data Scientist   \n",
       "6                                Lead Data Scientist   \n",
       "7                                Lead Data Scientist   \n",
       "8   Senior Data Scientist / Tech Lead - Data Science   \n",
       "9                        Senior Data Scientist - KPO   \n",
       "\n",
       "                                        JOB LOCATION  \\\n",
       "0              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "8                   Bangalore/Bengaluru, Delhi / NCR   \n",
       "9           Mumbai, Bangalore/Bengaluru, Delhi / NCR   \n",
       "\n",
       "                               COMPANY NAME  \\\n",
       "0                  Evalueserve.com Pvt. Ltd   \n",
       "1                    IBM India Pvt. Limited   \n",
       "2                            Superior Group   \n",
       "3                    IBM India Pvt. Limited   \n",
       "4  SMITHS DETECTION SYSTEMS PRIVATE LIMITED   \n",
       "5            Cognizer India Private Limited   \n",
       "6                    Zycus Infotech Pvt Ltd   \n",
       "7      TransOrg Solutions Services (P) Ltd.   \n",
       "8                              Confidential   \n",
       "9                   TalentCo Search Pvt Ltd   \n",
       "\n",
       "                                     JOB DESCRIPTION  \n",
       "0  Job description\\nJob Description\\nUnderstand a...  \n",
       "1                                                 --  \n",
       "2  Job description\\nProvide advanced analytical c...  \n",
       "3                                                 --  \n",
       "4                                                 --  \n",
       "5  Job description\\n\\nRoles and Responsibilities\\...  \n",
       "6  Job description\\nZycus is looking for applican...  \n",
       "7                                                 --  \n",
       "8  Job description\\nResponsibilities -\\nLead a te...  \n",
       "9  Job description\\n- Ability to understand a pro...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of data science job from naukari.com \n",
    "Data_Scientist = pd.DataFrame({})\n",
    "Data_Scientist['JOB TITLES']= job_titles\n",
    "Data_Scientist['JOB LOCATION'] = job_location\n",
    "Data_Scientist['COMPANY NAME'] = company_name \n",
    "Data_Scientist['JOB DESCRIPTION'] = job_description\n",
    "Data_Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.3- In this question you have to scrape data using the filters available on the webpage as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.naukri.com/'\n",
    "web_driver.get(url)\n",
    "#the url will open \n",
    "\n",
    "#inspect for Skill,Designations,Companies field\n",
    "job_search = web_driver.find_element_by_id('qsb-keyword-sugg')\n",
    "#this will write text on search bar\n",
    "job_search.send_keys('Data Scientist')\n",
    "\n",
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click to select location\n",
    "location_filter = web_driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i')\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the desired salary\n",
    "salary_filter = web_driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB TITLES</th>\n",
       "      <th>JOB LOCATION</th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Internship</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>iHackers Inc</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Agreeya</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Sr. Data Scientist</td>\n",
       "      <td>Noida, Pune, Mumbai (All Areas)</td>\n",
       "      <td>WEGARNER SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist - Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Immediate Openings For DATA Scientist with 6 T...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Entune IT Consulting Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JOB TITLES  \\\n",
       "0                          Data Scientist Internship   \n",
       "1                                     Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3                Data Scientist / Sr. Data Scientist   \n",
       "4  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "5                      Senior Data Scientist - Noida   \n",
       "6                                     Data Scientist   \n",
       "7  Immediate Openings For DATA Scientist with 6 T...   \n",
       "8              Data Scientist - Machine Learning/NLP   \n",
       "9              Data Scientist - Machine Learning/NLP   \n",
       "\n",
       "                                        JOB LOCATION  \\\n",
       "0                                          New Delhi   \n",
       "1                                   Gurgaon/Gurugram   \n",
       "2               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "3                    Noida, Pune, Mumbai (All Areas)   \n",
       "4               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "5                                              Noida   \n",
       "6                             Noida(Sector-59 Noida)   \n",
       "7  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9                                   Gurgaon/Gurugram   \n",
       "\n",
       "                                     COMPANY NAME EXPERIENCE  \n",
       "0                                    iHackers Inc    0-1 Yrs  \n",
       "1                         CBRE South Asia Pvt Ltd    2-4 Yrs  \n",
       "2                                         Agreeya    3-6 Yrs  \n",
       "3              WEGARNER SOLUTIONS PRIVATE LIMITED    0-5 Yrs  \n",
       "4                       GABA Consultancy services    0-0 Yrs  \n",
       "5  Optum Global Solutions (India) Private Limited    2-6 Yrs  \n",
       "6                    R Systems International Ltd.   5-10 Yrs  \n",
       "7            Entune IT Consulting Private Limited    5-8 Yrs  \n",
       "8                                          TalPro    2-6 Yrs  \n",
       "9                                          TalPro    2-4 Yrs  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the tag having job titles\n",
    "job_title = web_driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "job_titles = [] #empty list\n",
    "\n",
    "for i in job_title[0:10]:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "    \n",
    "#extract the tag having job location\n",
    "job_loc = web_driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "\n",
    "job_location = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for j in job_loc[0:10]:\n",
    "    job_location.append(j.text)\n",
    "\n",
    "    \n",
    "#extract the tag having company name\n",
    "company = web_driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "company_name = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having experience\n",
    "experience_req = web_driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "\n",
    "experience = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in experience_req[0:10]:\n",
    "    experience.append(i.text)\n",
    "\n",
    "\n",
    "# Make data frame of datanalyst job from naukari.com \n",
    "Data_Scientist = pd.DataFrame({})\n",
    "Data_Scientist['JOB TITLES']= job_titles\n",
    "Data_Scientist['JOB LOCATION'] = job_location\n",
    "Data_Scientist['COMPANY NAME'] = company_name \n",
    "Data_Scientist['EXPERIENCE'] = experience\n",
    "Data_Scientist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.4- Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.glassdoor.co.in/member/home/index.htm'\n",
    "web_driver.get(url)\n",
    "#the url will open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect for Job Title,Keyword,Company field\n",
    "job_search = web_driver.find_element_by_id(\"sc.keyword\")\n",
    "#this will write text on search bar\n",
    "job_search.send_keys('Data scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect for Job Title,Keyword,Company field\n",
    "job_location = web_driver.find_element_by_id(\"sc.location\")\n",
    "#this will write text on search bar\n",
    "job_location.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//span[@class='css-8zxfjs']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having company name\n",
    "company = web_driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']\")\n",
    "\n",
    "company_name = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having urls of all compaies\n",
    "url = web_driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']\")\n",
    "\n",
    "job_urls = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in url[0:10]:\n",
    "    job_urls.append(i.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--', '--', '--', '3.8', '--', '3.8', '--', '4.1', '4.1', '3.4']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = [] #Empty list\n",
    "for i in job_urls:\n",
    "    web_driver.get(i)\n",
    "    try:\n",
    "        rate = web_driver.find_element_by_xpath(\"//div[@class='css-16nw49e e11nt52q1']//span\")\n",
    "        rating.append(rate.text.replace('\\n','').replace('★', ''))\n",
    "    except:\n",
    "        rating.append('--')\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"8a2bfac8d7781ef3a05efea1273c0fcc\", element=\"0d4ac086-c5bc-4208-9c85-8a9b54d694cd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8a2bfac8d7781ef3a05efea1273c0fcc\", element=\"b42974bb-ed70-4609-824f-1034f2745222\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8a2bfac8d7781ef3a05efea1273c0fcc\", element=\"8138f0c5-62d2-499f-935b-06e5d1d73b93\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8a2bfac8d7781ef3a05efea1273c0fcc\", element=\"e792a613-2bf2-462f-9e6c-8102b32fc929\")>]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = web_driver.find_elements_by_xpath(\"//div[contains(text(),'d')]\")\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17d', '7d', '9d', '28d', '9d', '30d+', '2d', '30d+', '4d', '9d']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrap data when job was posted\n",
    "Time = [] #empty list\n",
    "\n",
    "days = web_driver.find_elements_by_xpath(\"//div[contains(text(),'d')]\")\n",
    "for i in days[0:10]:\n",
    "    Time.append(i.text)\n",
    "Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>TIME</th>\n",
       "      <th>RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>17d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Trained Education</td>\n",
       "      <td>7d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pixel Vision</td>\n",
       "      <td>9d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CRMNEXT</td>\n",
       "      <td>28d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emerging India Analytics</td>\n",
       "      <td>9d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Crowe</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>2d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>4d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Newgen Software</td>\n",
       "      <td>9d</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           COMPANY NAME  TIME RATING\n",
       "0  Liberin Technologies Private Limited   17d     --\n",
       "1                Data Trained Education    7d     --\n",
       "2                          Pixel Vision    9d     --\n",
       "3                               CRMNEXT   28d    3.8\n",
       "4              Emerging India Analytics    9d     --\n",
       "5                                 Crowe  30d+    3.8\n",
       "6          Salasar New Age Technologies    2d     --\n",
       "7                        Biz2Credit Inc  30d+    4.1\n",
       "8                              Ericsson    4d    4.1\n",
       "9                       Newgen Software    9d    3.4"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of datanalyst job from naukari.com \n",
    "Glassdoor1 = pd.DataFrame({})\n",
    "Glassdoor1['COMPANY NAME']= company_name\n",
    "Glassdoor1['TIME'] = Time[0:10]\n",
    "Glassdoor1['RATING'] = rating \n",
    "Glassdoor1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.5- Write a python program to scrape the salary data for Data Scientist designation in Noida location.You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.glassdoor.co.in/Salaries/index.htm'\n",
    "web_driver.get(url)\n",
    "#the url will open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect for Job Title,Keyword,Company field\n",
    "job_search = web_driver.find_element_by_id(\"KeywordSearch\")\n",
    "#this will write text on search bar\n",
    "job_search.send_keys('Data scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect for Job Title,Keyword,Company field\n",
    "job_location = web_driver.find_element_by_id(\"LocationSearch\")\n",
    "#this will write text on search bar\n",
    "job_location.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>SALARY NUMBER</th>\n",
       "      <th>AVERAGE SALARY</th>\n",
       "      <th>MINIMUM MAXIMUM SALARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>18 salaries</td>\n",
       "      <td>₹6,12,205 /yr</td>\n",
       "      <td>₹3L - ₹13L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>18 salaries</td>\n",
       "      <td>₹9,00,000 /yr</td>\n",
       "      <td>₹6L - ₹27L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹11,63,336 /yr</td>\n",
       "      <td>₹6L - ₹22L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹12,18,244 /yr</td>\n",
       "      <td>₹5L - ₹1Cr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹7,39,238 /yr</td>\n",
       "      <td>₹4L - ₹16L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹12,80,000 /yr</td>\n",
       "      <td>₹8L - ₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹13,20,960 /yr</td>\n",
       "      <td>₹8L - ₹20L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹8,63,750 /yr</td>\n",
       "      <td>₹5L - ₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹11,10,000 /yr</td>\n",
       "      <td>₹6L - ₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹13,28,697 /yr</td>\n",
       "      <td>₹4L - ₹22L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                COMPANY NAME SALARY NUMBER  AVERAGE SALARY  \\\n",
       "0  Tata Consultancy Services   18 salaries   ₹6,12,205 /yr   \n",
       "1                        IBM   18 salaries   ₹9,00,000 /yr   \n",
       "2                  Accenture   15 salaries  ₹11,63,336 /yr   \n",
       "3                  Delhivery   15 salaries  ₹12,18,244 /yr   \n",
       "4         Ericsson-Worldwide   14 salaries   ₹7,39,238 /yr   \n",
       "5         UnitedHealth Group   14 salaries  ₹12,80,000 /yr   \n",
       "6                      Optum   10 salaries  ₹13,20,960 /yr   \n",
       "7         Valiance Solutions   10 salaries   ₹8,63,750 /yr   \n",
       "8                EXL Service    9 salaries  ₹11,10,000 /yr   \n",
       "9     Optum Global Solutions    9 salaries  ₹13,28,697 /yr   \n",
       "\n",
       "  MINIMUM MAXIMUM SALARY  \n",
       "0             ₹3L - ₹13L  \n",
       "1             ₹6L - ₹27L  \n",
       "2             ₹6L - ₹22L  \n",
       "3             ₹5L - ₹1Cr  \n",
       "4             ₹4L - ₹16L  \n",
       "5             ₹8L - ₹15L  \n",
       "6             ₹8L - ₹20L  \n",
       "7             ₹5L - ₹15L  \n",
       "8             ₹6L - ₹15L  \n",
       "9             ₹4L - ₹22L  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the tag having company name\n",
    "company = web_driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "\n",
    "company_name = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "    \n",
    "#extract the tag having salary number\n",
    "num_sal = web_driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-auto']\")\n",
    "\n",
    "Salary_Number= [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in num_sal[0:10]:\n",
    "    Salary_Number.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having average salary \n",
    "avg_sal = web_driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "\n",
    "Average_salary = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in avg_sal[0:10]:\n",
    "    Average_salary.append(i.text.replace('\\n',''))\n",
    "\n",
    "    \n",
    "#extract the tag having minimum and maximum salary \n",
    "minmax_sal = web_driver.find_elements_by_xpath(\"//span[@class='d-block d-lg-none m-0 css-1b6bxoo']\")\n",
    "\n",
    "Min_Max_salary = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in minmax_sal[0:10]:\n",
    "    Min_Max_salary.append(i.text.replace('Range: ', ''))\n",
    "\n",
    "    \n",
    "# Make data frame of data science job from glassdoor\n",
    "Glassdoor2 = pd.DataFrame({})\n",
    "Glassdoor2['COMPANY NAME']= company_name\n",
    "Glassdoor2['SALARY NUMBER'] = Salary_Number\n",
    "Glassdoor2['AVERAGE SALARY'] = Average_salary \n",
    "Glassdoor2['MINIMUM MAXIMUM SALARY'] = Min_Max_salary \n",
    "Glassdoor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.6- Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "### 1. Brand\n",
    "### 2. Product Description\n",
    "### 3. Price\n",
    "### 4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.flipkart.com/'\n",
    "web_driver.get(url)\n",
    "#the url will open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not login button click\n",
    "notlogin_button = web_driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "notlogin_button.click()\n",
    "\n",
    "#inspect for product name field\n",
    "product_search = web_driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "#this will write text on search bar\n",
    "product_search.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=1',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=3']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the tag having urls of all pages\n",
    "url = web_driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']//a\")\n",
    "\n",
    "glasses_urls = [] #empty list\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in url[0:3]:\n",
    "    glasses_urls.append(i.get_attribute('href'))\n",
    "glasses_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND NAME</th>\n",
       "      <th>GLASS DESCRIPTION</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>DISCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wrogn</td>\n",
       "      <td>Mirrored Wayfarer Sunglasses (51)</td>\n",
       "      <td>₹663</td>\n",
       "      <td>73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (53)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹513</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (58)</td>\n",
       "      <td>₹474</td>\n",
       "      <td>68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Sports Sunglasses (73)</td>\n",
       "      <td>₹348</td>\n",
       "      <td>72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection, Mirrored, Gradient Retro Square...</td>\n",
       "      <td>₹246</td>\n",
       "      <td>87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wrogn</td>\n",
       "      <td>Mirrored Wayfarer Sunglasses (52)</td>\n",
       "      <td>₹695</td>\n",
       "      <td>73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized Retro Square Sunglasses (58)</td>\n",
       "      <td>₹474</td>\n",
       "      <td>55%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    BRAND NAME                                  GLASS DESCRIPTION PRICE  \\\n",
       "0        Wrogn                  Mirrored Wayfarer Sunglasses (51)  ₹663   \n",
       "1    ROYAL SON     Polarized, UV Protection Round Sunglasses (53)  ₹664   \n",
       "2    Elligator                UV Protection Round Sunglasses (54)  ₹295   \n",
       "3     Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹513   \n",
       "4     Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹758   \n",
       "..         ...                                                ...   ...   \n",
       "95   ROYAL SON          UV Protection Rectangular Sunglasses (58)  ₹474   \n",
       "96       NuVew               UV Protection Sports Sunglasses (73)  ₹348   \n",
       "97  PHENOMENAL  UV Protection, Mirrored, Gradient Retro Square...  ₹246   \n",
       "98       Wrogn                  Mirrored Wayfarer Sunglasses (52)  ₹695   \n",
       "99   ROYAL SON             Polarized Retro Square Sunglasses (58)  ₹474   \n",
       "\n",
       "   DISCOUNT  \n",
       "0      73%   \n",
       "1      66%   \n",
       "2      88%   \n",
       "3      35%   \n",
       "4      15%   \n",
       "..      ...  \n",
       "95     68%   \n",
       "96     72%   \n",
       "97     87%   \n",
       "98     73%   \n",
       "99     55%   \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brand_name = [] #empty list\n",
    "#extract the tag having brand name\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    brand = web_driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in brand:\n",
    "        Brand_name.append(i.text) #to remove extra data other than output we required\n",
    "Brand_Name = Brand_name[0:100]\n",
    "\n",
    "\n",
    "Description = [] #empty list\n",
    "#extract the tag having description\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    desp = web_driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    for i in desp:\n",
    "        Description.append(i.text) #to remove extra data other than output we required\n",
    "glass_description = Description[0:100]\n",
    "\n",
    "\n",
    "price = [] #empty list\n",
    "#extract the tag having price\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    pri = web_driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for i in pri[0:100]:\n",
    "        price.append(i.text) #to remove extra data other than output we required\n",
    "Price = price[0:100]\n",
    "\n",
    "\n",
    "discount = [] #empty list\n",
    "#extract the tag having discount\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    dis = web_driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    for i in dis[0:100]:\n",
    "        discount.append(i.text.replace('off','')) #to remove extra data other than output we required\n",
    "Discount = discount[0:100]\n",
    "\n",
    "\n",
    "# Make data frame of sunglasses from flipkart.com\n",
    "Sunglasses = pd.DataFrame({})\n",
    "Sunglasses['BRAND NAME']= Brand_Name\n",
    "Sunglasses['GLASS DESCRIPTION'] = glass_description\n",
    "Sunglasses['PRICE'] = Price \n",
    "Sunglasses['DISCOUNT'] = Discount \n",
    "Sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.7- Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\n",
    "\n",
    "#### 1. Rating \n",
    "#### 2. Review_summary \n",
    "#### 3. Full review\n",
    "### You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = ' https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace'\n",
    "web_driver.get(url)\n",
    "#the url will open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all rewiev button click\n",
    "all_review = web_driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\")\n",
    "all_review.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having urls of all pages\n",
    "url = web_driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']//a\")\n",
    "\n",
    "rev_urls = [] #empty list\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in url[0:11]:\n",
    "    rev_urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RATING</th>\n",
       "      <th>REVIEW SUMMARY</th>\n",
       "      <th>FULL REVIEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Everything is perfect pictures come out so cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>The ultimate performance\\nCamera is superb\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Excellent camera 📸 And Display touching very N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>A perfect phone and a good battery super camer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RATING         REVIEW SUMMARY  \\\n",
       "0       5              Brilliant   \n",
       "1       4         Simply awesome   \n",
       "2       4       Perfect product!   \n",
       "3       5              Fabulous!   \n",
       "4       3      Worth every penny   \n",
       "..    ...                    ...   \n",
       "95      5                 Super!   \n",
       "96      5              Fabulous!   \n",
       "97      5              Just wow!   \n",
       "98      5  Mind-blowing purchase   \n",
       "99      5              Excellent   \n",
       "\n",
       "                                          FULL REVIEW  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   This is my first iOS phone. I am very happy wi...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "96  Everything is perfect pictures come out so cle...  \n",
       "97  The ultimate performance\\nCamera is superb\\nTh...  \n",
       "98  Excellent camera 📸 And Display touching very N...  \n",
       "99  A perfect phone and a good battery super camer...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating = [] #empty list\n",
    "#extract the tag having rating\n",
    "for i in rev_urls:\n",
    "    web_driver.get(i)\n",
    "    rate = web_driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    for i in rate:\n",
    "        Rating.append(i.text) #to remove extra data other than output we required\n",
    "        \n",
    "Review_summary = [] #empty list\n",
    "#extract the tag having review summary\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    summary = web_driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    for i in summary:\n",
    "        Review_summary.append(i.text) #to remove extra data other than output we required\n",
    "\n",
    "Full_review = [] #empty list\n",
    "#extract the tag having Full_review\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    full = web_driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for i in full:\n",
    "        Full_review.append(i.text) #to remove extra data other than output we required\n",
    "\n",
    "\n",
    "# Make data frame of review of i-phone from flipkart.com\n",
    "REVIEWS = pd.DataFrame({})\n",
    "REVIEWS['RATING']= Rating[0:100]\n",
    "REVIEWS['REVIEW SUMMARY'] = Review_summary[0:100]\n",
    "REVIEWS['FULL REVIEW'] = Full_review[0:100] \n",
    "REVIEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.8- Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker :\n",
    "### 1. Brand\n",
    "### 2. Product Description\n",
    "### 3. Price\n",
    "### 4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.flipkart.com/'\n",
    "web_driver.get(url)\n",
    "#the url will open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not login button click\n",
    "notlogin_button = web_driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "notlogin_button.click()\n",
    "\n",
    "#inspect for product name field\n",
    "job_search = web_driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "#this will write text on search bar\n",
    "job_search.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=1',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=3',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=4',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=5']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the tag having urls of all pages\n",
    "url = web_driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']//a\")\n",
    "\n",
    "sneakers_urls = [] #empty list\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in url[0:5]:\n",
    "    sneakers_urls.append(i.get_attribute('href'))\n",
    "sneakers_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND NAME</th>\n",
       "      <th>sneakers DESCRIPTION</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>DISCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,219</td>\n",
       "      <td>67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹389</td>\n",
       "      <td>80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEHANOSA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹378</td>\n",
       "      <td>62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>168 Smart Red Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹323</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Edoeviv</td>\n",
       "      <td>Stylish lightweight shoe Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹3,994</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>India hub</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹448</td>\n",
       "      <td>80%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BRAND NAME                               sneakers DESCRIPTION   PRICE  \\\n",
       "0           DUCATI                                   Sneakers For Men  ₹1,219   \n",
       "1   luxury fashion  Luxury Fashionable casual sneaker shoes Sneake...    ₹389   \n",
       "2           Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...    ₹599   \n",
       "3         PEHANOSA                                   Sneakers For Men    ₹399   \n",
       "4          Numenzo                                   Sneakers For Men    ₹378   \n",
       "..             ...                                                ...     ...   \n",
       "95  luxury fashion     Casual Sneakers Shoes For Men Sneakers For Men    ₹399   \n",
       "96          BRUTON  168 Smart Red Lace-Ups Casuals for Men Sneaker...    ₹323   \n",
       "97         Edoeviv          Stylish lightweight shoe Sneakers For Men    ₹449   \n",
       "98            PUMA                                   Sneakers For Men  ₹3,994   \n",
       "99       India hub                                   Sneakers For Men    ₹448   \n",
       "\n",
       "   DISCOUNT  \n",
       "0      67%   \n",
       "1      80%   \n",
       "2      62%   \n",
       "3      60%   \n",
       "4      62%   \n",
       "..      ...  \n",
       "95     86%   \n",
       "96     75%   \n",
       "97     55%   \n",
       "98     50%   \n",
       "99     80%   \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brand_name = [] #empty list\n",
    "#extract the tag having brand name\n",
    "for i in sneakers_urls:\n",
    "    web_driver.get(i)\n",
    "    brand = web_driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in brand:\n",
    "        Brand_name.append(i.text) #to remove extra data other than output we required\n",
    "Brand_name\n",
    "\n",
    "\n",
    "Description = [] #empty list\n",
    "#extract the tag having description\n",
    "for i in sneakers_urls:\n",
    "    web_driver.get(i)\n",
    "    desp = web_driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    for i in desp:\n",
    "        Description.append(i.text) #to remove extra data other than output we required\n",
    "\n",
    "\n",
    "\n",
    "price = [] #empty list\n",
    "#extract the tag having price\n",
    "for i in sneakers_urls:\n",
    "    web_driver.get(i)\n",
    "    pri = web_driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for i in pri[0:100]:\n",
    "        price.append(i.text) #to remove extra data other than output we required\n",
    "\n",
    "\n",
    "discount = [] #empty list\n",
    "#extract the tag having discount\n",
    "for i in sneakers_urls:\n",
    "    web_driver.get(i)\n",
    "    dis = web_driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    for i in dis:\n",
    "        discount.append(i.text.replace('off','')) #to remove extra data other than output we required\n",
    "\n",
    "\n",
    "\n",
    "# Make data frame of sneakers from flipkart.com\n",
    "sneakers = pd.DataFrame({})\n",
    "sneakers['BRAND NAME']= Brand_name[0:100]\n",
    "sneakers['sneakers DESCRIPTION'] = Description[0:100]\n",
    "sneakers['PRICE'] = price[0:100] \n",
    "sneakers['DISCOUNT'] = discount[0:100] \n",
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.9- : Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black” And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.myntra.com/shoes'\n",
    "web_driver.get(url)\n",
    "#the url will open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click to select color\n",
    "color_filter = web_driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click to select price\n",
    "price_filter = web_driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A5349.0_10499.0_5349.0%20TO%2010499.0',\n",
       " 'https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A5349.0_10499.0_5349.0%20TO%2010499.0&p=2']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the tag having urls of all pages\n",
    "url = web_driver.find_elements_by_xpath(\"//ul[@class='pagination-container']//a\")\n",
    "\n",
    "shoes_urls = [] #empty list\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in url[0:2]:\n",
    "    shoes_urls.append(i.get_attribute('href'))\n",
    "shoes_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND NAME</th>\n",
       "      <th>SHOES DESCRIPTION</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Cell Fraction Fade Running</td>\n",
       "      <td>Rs. 5995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Renew Retaliation TR 3</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men BlazerLow '77 Sneakers</td>\n",
       "      <td>Rs. 7195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Unisex Project Rock Recruit</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Crater Remixa Sneakers</td>\n",
       "      <td>Rs. 5495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 6293Rs. 8990(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Xtep</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 5599Rs. 7999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Velvet Loafers</td>\n",
       "      <td>Rs. 5399Rs. 5999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Xtep</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 6293Rs. 8990(30% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              BRAND NAME               SHOES DESCRIPTION  \\\n",
       "0                   Puma  Men Cell Fraction Fade Running   \n",
       "1                   Nike      Men Renew Retaliation TR 3   \n",
       "2                   Nike      Men BlazerLow '77 Sneakers   \n",
       "3           UNDER ARMOUR     Unisex Project Rock Recruit   \n",
       "4                   Nike      Men Crater Remixa Sneakers   \n",
       "..                   ...                             ...   \n",
       "95                  Geox       Men Leather Driving Shoes   \n",
       "96                  Xtep               Men Running Shoes   \n",
       "97  Heel & Buckle London             Men Leather Loafers   \n",
       "98  Heel & Buckle London              Men Velvet Loafers   \n",
       "99                  Xtep               Men Running Shoes   \n",
       "\n",
       "                        PRICE  \n",
       "0                    Rs. 5995  \n",
       "1                    Rs. 6999  \n",
       "2                    Rs. 7195  \n",
       "3                    Rs. 9999  \n",
       "4                    Rs. 5495  \n",
       "..                        ...  \n",
       "95  Rs. 6293Rs. 8990(30% OFF)  \n",
       "96  Rs. 5599Rs. 7999(30% OFF)  \n",
       "97                   Rs. 9999  \n",
       "98  Rs. 5399Rs. 5999(10% OFF)  \n",
       "99  Rs. 6293Rs. 8990(30% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brand_name = [] #empty list\n",
    "#extract the tag having brand name\n",
    "for i in shoes_urls:\n",
    "    web_driver.get(i)\n",
    "    brand = web_driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    for i in brand:\n",
    "        Brand_name.append(i.text) #to remove extra data other than output we required\n",
    "\n",
    "\n",
    "Description = [] #empty list\n",
    "#extract the tag having description\n",
    "for i in shoes_urls:\n",
    "    web_driver.get(i)\n",
    "    desp = web_driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "    for i in desp:\n",
    "        Description.append(i.text) #to remove extra data other than output we required\n",
    "        \n",
    "\n",
    "price = [] #empty list\n",
    "#extract the tag having price\n",
    "for i in shoes_urls:\n",
    "    web_driver.get(i)\n",
    "    pri = web_driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    for i in pri[0:100]:\n",
    "        price.append(i.text) #to remove extra data other than output we required\n",
    "        \n",
    "\n",
    "# Make data frame of shoes from myntra.com\n",
    "shoes = pd.DataFrame({})\n",
    "shoes['BRAND NAME']= Brand_name\n",
    "shoes['SHOES DESCRIPTION'] = Description\n",
    "shoes['PRICE'] = price \n",
    "shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.10- Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.amazon.in/'\n",
    "web_driver.get(url)\n",
    "#the url will open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect for product name field\n",
    "product_search = web_driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "#this will write text on search bar\n",
    "product_search.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "search_button = web_driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click to select cpu type i7\n",
    "i7_filter = web_driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/ul[6]/li[26]/span/a/div/label/i')\n",
    "i7_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click to select cpu type i9\n",
    "i9_filter = web_driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/ul[6]/li[28]/span/a/div/label/i')\n",
    "i9_filter.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HP Envy 11th Gen Core i7 Processor 13.3-inch (33.78 cms) FHD Touchscreen Laptop (16GB/1TB SSD/Win 10/NVIDIA MX450 2GB/Natural Silver/1.3 kg), 13-ba1018TX',\n",
       " 'Lenovo Yoga 7 11th Gen Intel Core i7-1165G7 14\" (35.56cm) FHD IPS 2-in-1 Touchscreen Laptop (16GB/512GB SSD/Windows 10/MS Office/Lenovo Digital Pen/Fingerprint Reader/Slate Grey/1.43Kg), 82BH004HIN',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i7-10510U 10th Gen 14-inch (35.56 cms) Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AF+Webcam',\n",
       " 'HP Pavilion (2021) Thin & Light 11th Gen Core i7 Laptop, 16 GB RAM, 1TB SSD, Iris Xe Graphics, 14\" (35.56cms) FHD Screen, Windows 10, MS Office, Backlit Keyboard (14-dv0058TU)',\n",
       " 'MSI GF65 Thin, Intel i7-10750H, 15.6\" FHD (39.6 cm) IPS-Level 144Hz Panel Laptop (16GB/512GB NVMe SSD/Windows 10 Home/Nvidia GTX1660 Ti 6GB GDDR6/Black/1.86Kg), 10SDR-1280IN',\n",
       " 'ASUS TUF Gaming F15 (2020), 15.6-inch (39.62 cms) FHD 144Hz, Intel Core i7-10870H 10th Gen, NVIDIA GeForce GTX 1650 4GB Graphics, Gaming Laptop(8GB/512GB SSDWindows 10/Gray/2.3 Kg), FX566LH-HN255T',\n",
       " 'HP Envy 11th Gen Core i7 Processor 13.3-inch (33.78 cms) FHD Touchscreen Laptop (16GB/1TB SSD/Win 10/NVIDIA MX450 2GB/Natural Silver/1.3 kg), 13-ba1018TX',\n",
       " 'Life Digital Laptop 15.6-inch (39.62 cms) (Intel Core i7, 4GB RAM, 256GB SSD, Windows 10), ZED AIR CX7',\n",
       " 'MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm) FHD IPS-Level 144Hz Panel Laptop (8GB/512GB NVMe SSD/Windows 10 Home/Nvidia GTX1650 4GB GDDR6/Black/2.2Kg), 10SCXR-654IN',\n",
       " 'Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 14\"(35.56cm) FHD IPS 2-in-1 Touchscreen Laptop(16GB/512GB SSD/Windows 10/MS Office/Lenovo Digital Pen/Fingerprint Reader/Graphite Grey/1.5Kg), 82HS0092IN']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the tag having brand name\n",
    "brand = web_driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "\n",
    "brand_name = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in brand[0:10]:\n",
    "    brand_name.append(i.text)\n",
    "brand_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having urls of all compaies\n",
    "url = web_driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "\n",
    "rating_urls = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in url[0:10]:\n",
    "    rating_urls.append(i.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.1 out of 5',\n",
       " '4.2 out of 5',\n",
       " '4.4 out of 5',\n",
       " '4.3 out of 5',\n",
       " '3.6 out of 5',\n",
       " '4.2 out of 5',\n",
       " '4.1 out of 5',\n",
       " '3.8 out of 5',\n",
       " '4.6 out of 5',\n",
       " '4 out of 5']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = [] #empty list\n",
    "#extract the tag having rating\n",
    "for i in rating_urls:\n",
    "    web_driver.get(i)\n",
    "    rate = web_driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "    for i in rate[0:10]:\n",
    "        rating.append(i.text) #to remove extra data other than output we required\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹1,09,990.00',\n",
       " '₹1,03,100.00',\n",
       " '₹84,990.00',\n",
       " '₹81,990.00',\n",
       " '₹71,990.00',\n",
       " '₹1,09,990.00',\n",
       " '₹34,990.00',\n",
       " '₹74,990.00',\n",
       " '₹90,950.00']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = [] #empty list\n",
    "#extract the tag having rating\n",
    "for i in rating_urls:\n",
    "    web_driver.get(i)\n",
    "    pri = web_driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-price priceBlockBuyingPriceString']\")\n",
    "    for i in pri[0:10]:\n",
    "        price.append(i.text) #to remove extra data other than output we required\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND NAME</th>\n",
       "      <th>RATING</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>₹1,09,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7-1165G7 14...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>₹1,03,100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>₹84,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>₹81,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSI GF65 Thin, Intel i7-10750H, 15.6\" FHD (39....</td>\n",
       "      <td>3.6 out of 5</td>\n",
       "      <td>₹71,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F15 (2020), 15.6-inch (39.62 c...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>₹1,09,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>₹34,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "      <td>₹74,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm...</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "      <td>₹90,950.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          BRAND NAME        RATING  \\\n",
       "0  HP Envy 11th Gen Core i7 Processor 13.3-inch (...  4.1 out of 5   \n",
       "1  Lenovo Yoga 7 11th Gen Intel Core i7-1165G7 14...  4.2 out of 5   \n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.4 out of 5   \n",
       "3  HP Pavilion (2021) Thin & Light 11th Gen Core ...  4.3 out of 5   \n",
       "4  MSI GF65 Thin, Intel i7-10750H, 15.6\" FHD (39....  3.6 out of 5   \n",
       "5  ASUS TUF Gaming F15 (2020), 15.6-inch (39.62 c...  4.2 out of 5   \n",
       "6  HP Envy 11th Gen Core i7 Processor 13.3-inch (...  4.1 out of 5   \n",
       "7  Life Digital Laptop 15.6-inch (39.62 cms) (Int...  3.8 out of 5   \n",
       "8  MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm...  4.6 out of 5   \n",
       "\n",
       "          PRICE  \n",
       "0  ₹1,09,990.00  \n",
       "1  ₹1,03,100.00  \n",
       "2    ₹84,990.00  \n",
       "3    ₹81,990.00  \n",
       "4    ₹71,990.00  \n",
       "5  ₹1,09,990.00  \n",
       "6    ₹34,990.00  \n",
       "7    ₹74,990.00  \n",
       "8    ₹90,950.00  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of shoes from myntra.com\n",
    "LAPTOP = pd.DataFrame({})\n",
    "LAPTOP['BRAND NAME']= brand_name[0:9]\n",
    "LAPTOP['RATING'] = rating[0:9]\n",
    "LAPTOP['PRICE'] = price[0:9]\n",
    "LAPTOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
