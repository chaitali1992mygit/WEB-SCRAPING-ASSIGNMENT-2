{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\chaitali nakade\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\chaitali nakade\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "#install selenium\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all neccessory libreries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "libreries imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.1-  Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” \n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get url in web driver first\n",
    "url = 'https://www.naukri.com/'\n",
    "web_driver.get(url)\n",
    "#the url will open \n",
    "\n",
    "#inspect for Skill,Designations,Companies field\n",
    "job_search = web_driver.find_element_by_id('qsb-keyword-sugg')\n",
    "#this will write text on search bar\n",
    "job_search.send_keys('Data Analyst')\n",
    "\n",
    "#find element for job location\n",
    "search_location = web_driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_location.send_keys('Bangalore')\n",
    "\n",
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB TITLES</th>\n",
       "      <th>JOB LOCATION</th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst - Einstein Analytics</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Enquero</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - 0-2 years (6 month contract)</td>\n",
       "      <td>New Delhi, Gurgaon/Gurugram, Chennai, Bangalor...</td>\n",
       "      <td>NIUM INDIA PRIVATE LIMITED</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>CAREERLABS TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengal...</td>\n",
       "      <td>Nx-DT</td>\n",
       "      <td>10-16 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SQL Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Business Analyst- Data Science</td>\n",
       "      <td>Bangalore/Bengaluru(Whitefield)</td>\n",
       "      <td>Evalueserve.com Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business/Data Analyst - Colleague Experience &amp;...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Vmware</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Telstra India Pvt Ltd</td>\n",
       "      <td>7-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst (SQL+Predictive Analytics+ Python)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JOB TITLES  \\\n",
       "0           Senior Data Analyst - Einstein Analytics   \n",
       "1        Data Analyst - 0-2 years (6 month contract)   \n",
       "2                                       Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4                                Senior Data Analyst   \n",
       "5                                   SQL Data Analyst   \n",
       "6              Senior Business Analyst- Data Science   \n",
       "7  Business/Data Analyst - Colleague Experience &...   \n",
       "8                                Senior Data Analyst   \n",
       "9    Data Analyst (SQL+Predictive Analytics+ Python)   \n",
       "\n",
       "                                        JOB LOCATION  \\\n",
       "0        Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "1  New Delhi, Gurgaon/Gurugram, Chennai, Bangalor...   \n",
       "2            Bangalore/Bengaluru\\n(WFH during Covid)   \n",
       "3                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "4  Hyderabad/Secunderabad, Pune, Bangalore/Bengal...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                    Bangalore/Bengaluru(Whitefield)   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                              COMPANY NAME EXPERIENCE  \n",
       "0                                  Enquero    3-5 Yrs  \n",
       "1               NIUM INDIA PRIVATE LIMITED    0-2 Yrs  \n",
       "2  CAREERLABS TECHNOLOGIES PRIVATE LIMITED    0-3 Yrs  \n",
       "3           Tata Consultancy Services Ltd.    4-8 Yrs  \n",
       "4                                    Nx-DT  10-16 Yrs  \n",
       "5                                   NetApp    3-7 Yrs  \n",
       "6                 Evalueserve.com Pvt. Ltd    2-7 Yrs  \n",
       "7                                   Vmware    3-8 Yrs  \n",
       "8                    Telstra India Pvt Ltd    7-8 Yrs  \n",
       "9                             AVE-Promagne    1-3 Yrs  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the tag having job titles\n",
    "job_title = web_driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "job_titles = [] #empty list\n",
    "\n",
    "for i in job_title[0:10]:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "    \n",
    "#extract the tag having job location\n",
    "job_loc = web_driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "\n",
    "job_location = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for j in job_loc[0:10]:\n",
    "    job_location.append(j.text)\n",
    "\n",
    "    \n",
    "#extract the tag having company name\n",
    "company = web_driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "company_name = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having experience\n",
    "experience_req = web_driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "\n",
    "experience = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in experience_req[0:10]:\n",
    "    experience.append(i.text)\n",
    "\n",
    "# Make data frame of datanalyst job from naukari.com \n",
    "Data_Analyst = pd.DataFrame({})\n",
    "Data_Analyst['JOB TITLES']= job_titles\n",
    "Data_Analyst['JOB LOCATION'] = job_location\n",
    "Data_Analyst['COMPANY NAME'] = company_name \n",
    "Data_Analyst['EXPERIENCE'] = experience\n",
    "Data_Analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.2- Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter \n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get url in web driver first\n",
    "url = 'https://www.naukri.com/'\n",
    "web_driver.get(url)\n",
    "#the url will open \n",
    "\n",
    "#inspect for Skill,Designations,Companies field\n",
    "job_search = web_driver.find_element_by_id('qsb-keyword-sugg')\n",
    "#this will write text on search bar\n",
    "job_search.send_keys('Data Scientist')\n",
    "\n",
    "#find element for job location\n",
    "search_location = web_driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_location.send_keys('Bangalore')\n",
    "\n",
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having job titles\n",
    "job_title = web_driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "job_titles = [] #empty list\n",
    "\n",
    "for i in job_title[0:10]:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "    \n",
    "#extract the tag having job location\n",
    "job_loc = web_driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "\n",
    "job_location = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in job_loc[0:10]:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "    \n",
    "#extract the tag having company name\n",
    "company = web_driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "company_name = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having urls of all compaies\n",
    "url = web_driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_urls = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in url[0:10]:\n",
    "    job_urls.append(i.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = [] #Empty list\n",
    "for i in job_urls:\n",
    "    web_driver.get(i)\n",
    "    try:\n",
    "        job = web_driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "        job_description.append(job.text)\n",
    "    except:\n",
    "        job_description.append('--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(job_location),len(company_name),len(job_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB TITLES</th>\n",
       "      <th>JOB LOCATION</th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>JOB DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist- Senior Business Analyst/Lead A...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Evalueserve.com Pvt. Ltd</td>\n",
       "      <td>Job description\\nJob Description\\nUnderstand a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Data Scientist - Retail Industry</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior/ Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Superior Group</td>\n",
       "      <td>Job description\\nProvide advanced analytical c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>SMITHS DETECTION SYSTEMS PRIVATE LIMITED</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cognizer India Private Limited</td>\n",
       "      <td>Job description\\n\\nRoles and Responsibilities\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Zycus Infotech Pvt Ltd</td>\n",
       "      <td>Job description\\nZycus is looking for applican...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>TransOrg Solutions Services (P) Ltd.</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist / Tech Lead - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Job description\\nResponsibilities -\\nLead a te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist - KPO</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>TalentCo Search Pvt Ltd</td>\n",
       "      <td>Job description\\n- Ability to understand a pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JOB TITLES  \\\n",
       "0  Data Scientist- Senior Business Analyst/Lead A...   \n",
       "1              Lead Data Scientist - Retail Industry   \n",
       "2                        Senior/ Lead Data Scientist   \n",
       "3                 Data Scientist: Advanced Analytics   \n",
       "4                              Senior Data Scientist   \n",
       "5                              Senior Data Scientist   \n",
       "6                                Lead Data Scientist   \n",
       "7                                Lead Data Scientist   \n",
       "8   Senior Data Scientist / Tech Lead - Data Science   \n",
       "9                        Senior Data Scientist - KPO   \n",
       "\n",
       "                                        JOB LOCATION  \\\n",
       "0              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "8                   Bangalore/Bengaluru, Delhi / NCR   \n",
       "9           Mumbai, Bangalore/Bengaluru, Delhi / NCR   \n",
       "\n",
       "                               COMPANY NAME  \\\n",
       "0                  Evalueserve.com Pvt. Ltd   \n",
       "1                    IBM India Pvt. Limited   \n",
       "2                            Superior Group   \n",
       "3                    IBM India Pvt. Limited   \n",
       "4  SMITHS DETECTION SYSTEMS PRIVATE LIMITED   \n",
       "5            Cognizer India Private Limited   \n",
       "6                    Zycus Infotech Pvt Ltd   \n",
       "7      TransOrg Solutions Services (P) Ltd.   \n",
       "8                              Confidential   \n",
       "9                   TalentCo Search Pvt Ltd   \n",
       "\n",
       "                                     JOB DESCRIPTION  \n",
       "0  Job description\\nJob Description\\nUnderstand a...  \n",
       "1                                                 --  \n",
       "2  Job description\\nProvide advanced analytical c...  \n",
       "3                                                 --  \n",
       "4                                                 --  \n",
       "5  Job description\\n\\nRoles and Responsibilities\\...  \n",
       "6  Job description\\nZycus is looking for applican...  \n",
       "7                                                 --  \n",
       "8  Job description\\nResponsibilities -\\nLead a te...  \n",
       "9  Job description\\n- Ability to understand a pro...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of data science job from naukari.com \n",
    "Data_Scientist = pd.DataFrame({})\n",
    "Data_Scientist['JOB TITLES']= job_titles\n",
    "Data_Scientist['JOB LOCATION'] = job_location\n",
    "Data_Scientist['COMPANY NAME'] = company_name \n",
    "Data_Scientist['JOB DESCRIPTION'] = job_description\n",
    "Data_Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.3- In this question you have to scrape data using the filters available on the webpage as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.naukri.com/'\n",
    "web_driver.get(url)\n",
    "#the url will open \n",
    "\n",
    "#inspect for Skill,Designations,Companies field\n",
    "job_search = web_driver.find_element_by_id('qsb-keyword-sugg')\n",
    "#this will write text on search bar\n",
    "job_search.send_keys('Data Scientist')\n",
    "\n",
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click to select location\n",
    "location_filter = web_driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i')\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the desired salary\n",
    "salary_filter = web_driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB TITLES</th>\n",
       "      <th>JOB LOCATION</th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Internship</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>iHackers Inc</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Agreeya</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Sr. Data Scientist</td>\n",
       "      <td>Noida, Pune, Mumbai (All Areas)</td>\n",
       "      <td>WEGARNER SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist - Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Immediate Openings For DATA Scientist with 6 T...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Entune IT Consulting Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JOB TITLES  \\\n",
       "0                          Data Scientist Internship   \n",
       "1                                     Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3                Data Scientist / Sr. Data Scientist   \n",
       "4  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "5                      Senior Data Scientist - Noida   \n",
       "6                                     Data Scientist   \n",
       "7  Immediate Openings For DATA Scientist with 6 T...   \n",
       "8              Data Scientist - Machine Learning/NLP   \n",
       "9              Data Scientist - Machine Learning/NLP   \n",
       "\n",
       "                                        JOB LOCATION  \\\n",
       "0                                          New Delhi   \n",
       "1                                   Gurgaon/Gurugram   \n",
       "2               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "3                    Noida, Pune, Mumbai (All Areas)   \n",
       "4               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "5                                              Noida   \n",
       "6                             Noida(Sector-59 Noida)   \n",
       "7  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9                                   Gurgaon/Gurugram   \n",
       "\n",
       "                                     COMPANY NAME EXPERIENCE  \n",
       "0                                    iHackers Inc    0-1 Yrs  \n",
       "1                         CBRE South Asia Pvt Ltd    2-4 Yrs  \n",
       "2                                         Agreeya    3-6 Yrs  \n",
       "3              WEGARNER SOLUTIONS PRIVATE LIMITED    0-5 Yrs  \n",
       "4                       GABA Consultancy services    0-0 Yrs  \n",
       "5  Optum Global Solutions (India) Private Limited    2-6 Yrs  \n",
       "6                    R Systems International Ltd.   5-10 Yrs  \n",
       "7            Entune IT Consulting Private Limited    5-8 Yrs  \n",
       "8                                          TalPro    2-6 Yrs  \n",
       "9                                          TalPro    2-4 Yrs  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the tag having job titles\n",
    "job_title = web_driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "job_titles = [] #empty list\n",
    "\n",
    "for i in job_title[0:10]:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "    \n",
    "#extract the tag having job location\n",
    "job_loc = web_driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "\n",
    "job_location = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for j in job_loc[0:10]:\n",
    "    job_location.append(j.text)\n",
    "\n",
    "    \n",
    "#extract the tag having company name\n",
    "company = web_driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "company_name = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having experience\n",
    "experience_req = web_driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "\n",
    "experience = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in experience_req[0:10]:\n",
    "    experience.append(i.text)\n",
    "\n",
    "\n",
    "# Make data frame of datanalyst job from naukari.com \n",
    "Data_Scientist = pd.DataFrame({})\n",
    "Data_Scientist['JOB TITLES']= job_titles\n",
    "Data_Scientist['JOB LOCATION'] = job_location\n",
    "Data_Scientist['COMPANY NAME'] = company_name \n",
    "Data_Scientist['EXPERIENCE'] = experience\n",
    "Data_Scientist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.4- Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.glassdoor.co.in/member/home/index.htm'\n",
    "web_driver.get(url)\n",
    "#the url will open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect for Job Title,Keyword,Company field\n",
    "job_search = web_driver.find_element_by_id(\"sc.keyword\")\n",
    "#this will write text on search bar\n",
    "job_search.send_keys('Data scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect for Job Title,Keyword,Company field\n",
    "job_location = web_driver.find_element_by_id(\"sc.location\")\n",
    "#this will write text on search bar\n",
    "job_location.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//span[@class='css-8zxfjs']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having company name\n",
    "company = web_driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']\")\n",
    "\n",
    "company_name = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.glassdoor.co.in/partner/jobListing.htm?pos=101&ao=1136043&s=58&guid=0000017b3b47b272aa8c81c2f89a05b4&src=GD_JOB_AD&t=SR&vt=w&uido=8B09261858B8B80BBD360A0C01F7EB99&ea=1&cs=1_afcca6e9&cb=1628787160251&jobListingId=1007200389479&jrtk=2-0-1fctkfcmjhiho801-1fctkfcnsu3pk800-97d4c65035600d81',\n",
       " 'https://www.glassdoor.co.in/partner/jobListing.htm?pos=102&ao=1136043&s=58&guid=0000017b3b47b272aa8c81c2f89a05b4&src=GD_JOB_AD&t=SR&vt=w&uido=8B09261858B8B80BBD360A0C01F7EB99&ea=1&cs=1_885542ed&cb=1628787160252&jobListingId=1007223625926&jrtk=2-0-1fctkfcmjhiho801-1fctkfcnsu3pk800-8f431e7a43bcc483',\n",
       " 'https://www.glassdoor.co.in/partner/jobListing.htm?pos=103&ao=1136043&s=58&guid=0000017b3b47b272aa8c81c2f89a05b4&src=GD_JOB_AD&t=SR&vt=w&uido=8B09261858B8B80BBD360A0C01F7EB99&ea=1&cs=1_2282d0d4&cb=1628787160252&jobListingId=1007219231719&jrtk=2-0-1fctkfcmjhiho801-1fctkfcnsu3pk800-97e5e173cec15330',\n",
       " 'https://www.glassdoor.co.in/partner/jobListing.htm?pos=104&ao=1136043&s=58&guid=0000017b3b47b272aa8c81c2f89a05b4&src=GD_JOB_AD&t=SR&vt=w&uido=8B09261858B8B80BBD360A0C01F7EB99&ea=1&cs=1_c52d8b15&cb=1628787160254&jobListingId=1007181085665&jrtk=2-0-1fctkfcmjhiho801-1fctkfcnsu3pk800-c5ebf3c133ebe75f',\n",
       " 'https://www.glassdoor.co.in/partner/jobListing.htm?pos=105&ao=1136043&s=58&guid=0000017b3b47b272aa8c81c2f89a05b4&src=GD_JOB_AD&t=SR&vt=w&uido=8B09261858B8B80BBD360A0C01F7EB99&cs=1_773159b9&cb=1628787160252&jobListingId=1007095133299&jrtk=2-0-1fctkfcmjhiho801-1fctkfcnsu3pk800-84db922a59ad7885',\n",
       " 'https://www.glassdoor.co.in/partner/jobListing.htm?pos=106&ao=1136043&s=58&guid=0000017b3b47b272aa8c81c2f89a05b4&src=GD_JOB_AD&t=SR&vt=w&uido=8B09261858B8B80BBD360A0C01F7EB99&ea=1&cs=1_15c08c2c&cb=1628787160254&jobListingId=1007219665646&jrtk=2-0-1fctkfcmjhiho801-1fctkfcnsu3pk800-f48b990bb3cba778',\n",
       " 'https://www.glassdoor.co.in/partner/jobListing.htm?pos=107&ao=1136043&s=58&guid=0000017b3b47b272aa8c81c2f89a05b4&src=GD_JOB_AD&t=SR&vt=w&uido=8B09261858B8B80BBD360A0C01F7EB99&cs=1_2d13f870&cb=1628787160253&jobListingId=1006461286442&jrtk=2-0-1fctkfcmjhiho801-1fctkfcnsu3pk800-a1ea358f023a69b7',\n",
       " 'https://www.glassdoor.co.in/partner/jobListing.htm?pos=108&ao=1136043&s=58&guid=0000017b3b47b272aa8c81c2f89a05b4&src=GD_JOB_AD&t=SR&vt=w&uido=8B09261858B8B80BBD360A0C01F7EB99&ea=1&cs=1_3c5bd64d&cb=1628787160258&jobListingId=1006687249100&jrtk=2-0-1fctkfcmjhiho801-1fctkfcnsu3pk800-94036c835379de77',\n",
       " 'https://www.glassdoor.co.in/partner/jobListing.htm?pos=109&ao=1136043&s=58&guid=0000017b3b47b272aa8c81c2f89a05b4&src=GD_JOB_AD&t=SR&vt=w&uido=8B09261858B8B80BBD360A0C01F7EB99&cs=1_1c6bf527&cb=1628787160253&jobListingId=1007230855102&jrtk=2-0-1fctkfcmjhiho801-1fctkfcnsu3pk800-409b6a371f63d0fe',\n",
       " 'https://www.glassdoor.co.in/partner/jobListing.htm?pos=110&ao=1136043&s=58&guid=0000017b3b47b272aa8c81c2f89a05b4&src=GD_JOB_AD&t=SR&vt=w&uido=8B09261858B8B80BBD360A0C01F7EB99&cs=1_eff3dac9&cb=1628787160254&jobListingId=1006624053994&jrtk=2-0-1fctkfcmjhiho801-1fctkfcnsu3pk800-a8cb856cd397a474']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the tag having urls of all compaies\n",
    "url = web_driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']\")\n",
    "\n",
    "job_urls = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in url[0:10]:\n",
    "    job_urls.append(i.get_attribute('href'))\n",
    "job_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--', '--', '--', '--', '3.8', '--', '5.0', '4.1', '3.8', '--']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = [] #Empty list\n",
    "for i in job_urls:\n",
    "    web_driver.get(i)\n",
    "    try:\n",
    "        rate = web_driver.find_element_by_xpath(\"//div[@class='css-16nw49e e11nt52q1']//span\")\n",
    "        rating.append(rate.text.replace('\\n','').replace('★', ''))\n",
    "    except:\n",
    "        rating.append('--')\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap data when job was posted\n",
    "Time = [] #empty list\n",
    "\n",
    "days = web_driver.find_elements_by_xpath(\"//div[contains(text(),'d')]\")\n",
    "for i in days[0:10]:\n",
    "    Time.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>TIME</th>\n",
       "      <th>RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>16d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Trained Education</td>\n",
       "      <td>27d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emerging India Analytics</td>\n",
       "      <td>6d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pixel Vision</td>\n",
       "      <td>8d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>8d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Uncodemy</td>\n",
       "      <td>30d+</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CRMNEXT</td>\n",
       "      <td>27d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           COMPANY NAME  TIME RATING\n",
       "0  Liberin Technologies Private Limited   16d     --\n",
       "1                Data Trained Education   27d     --\n",
       "2              Emerging India Analytics    6d     --\n",
       "3                          Pixel Vision    8d     --\n",
       "4                                          8d    3.8\n",
       "5                              Uncodemy  30d+     --\n",
       "6                              Techlive  30d+    5.0\n",
       "7                        Biz2Credit Inc  30d+    4.1\n",
       "8                               CRMNEXT   27d    3.8\n",
       "9          Salasar New Age Technologies  30d+     --"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of datanalyst job from naukari.com \n",
    "Glassdoor1 = pd.DataFrame({})\n",
    "Glassdoor1['COMPANY NAME']= company_name\n",
    "Glassdoor1['TIME'] = Time\n",
    "Glassdoor1['RATING'] = rating \n",
    "Glassdoor1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.5- Write a python program to scrape the salary data for Data Scientist designation in Noida location.You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.glassdoor.co.in/Salaries/index.htm'\n",
    "web_driver.get(url)\n",
    "#the url will open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect for Job Title,Keyword,Company field\n",
    "job_search = web_driver.find_element_by_id(\"KeywordSearch\")\n",
    "#this will write text on search bar\n",
    "job_search.send_keys('Data scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect for Job Title,Keyword,Company field\n",
    "job_location = web_driver.find_element_by_id(\"LocationSearch\")\n",
    "#this will write text on search bar\n",
    "job_location.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>SALARY NUMBER</th>\n",
       "      <th>AVERAGE SALARY</th>\n",
       "      <th>MINIMUM MAXIMUM SALARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>18 salaries</td>\n",
       "      <td>₹6,12,205 /yr</td>\n",
       "      <td>₹3L - ₹13L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>18 salaries</td>\n",
       "      <td>₹9,00,000 /yr</td>\n",
       "      <td>₹6L - ₹27L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹11,63,336 /yr</td>\n",
       "      <td>₹6L - ₹22L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹12,18,244 /yr</td>\n",
       "      <td>₹5L - ₹1Cr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹7,39,238 /yr</td>\n",
       "      <td>₹4L - ₹16L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹12,80,000 /yr</td>\n",
       "      <td>₹8L - ₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹13,20,960 /yr</td>\n",
       "      <td>₹8L - ₹20L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹8,63,750 /yr</td>\n",
       "      <td>₹5L - ₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹11,10,000 /yr</td>\n",
       "      <td>₹6L - ₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹13,28,697 /yr</td>\n",
       "      <td>₹4L - ₹22L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                COMPANY NAME SALARY NUMBER  AVERAGE SALARY  \\\n",
       "0  Tata Consultancy Services   18 salaries   ₹6,12,205 /yr   \n",
       "1                        IBM   18 salaries   ₹9,00,000 /yr   \n",
       "2                  Accenture   15 salaries  ₹11,63,336 /yr   \n",
       "3                  Delhivery   15 salaries  ₹12,18,244 /yr   \n",
       "4         Ericsson-Worldwide   14 salaries   ₹7,39,238 /yr   \n",
       "5         UnitedHealth Group   14 salaries  ₹12,80,000 /yr   \n",
       "6                      Optum   10 salaries  ₹13,20,960 /yr   \n",
       "7         Valiance Solutions   10 salaries   ₹8,63,750 /yr   \n",
       "8                EXL Service    9 salaries  ₹11,10,000 /yr   \n",
       "9     Optum Global Solutions    9 salaries  ₹13,28,697 /yr   \n",
       "\n",
       "  MINIMUM MAXIMUM SALARY  \n",
       "0             ₹3L - ₹13L  \n",
       "1             ₹6L - ₹27L  \n",
       "2             ₹6L - ₹22L  \n",
       "3             ₹5L - ₹1Cr  \n",
       "4             ₹4L - ₹16L  \n",
       "5             ₹8L - ₹15L  \n",
       "6             ₹8L - ₹20L  \n",
       "7             ₹5L - ₹15L  \n",
       "8             ₹6L - ₹15L  \n",
       "9             ₹4L - ₹22L  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the tag having company name\n",
    "company = web_driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "\n",
    "company_name = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "    \n",
    "#extract the tag having salary number\n",
    "num_sal = web_driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-auto']\")\n",
    "\n",
    "Salary_Number= [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in num_sal[0:10]:\n",
    "    Salary_Number.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having average salary \n",
    "avg_sal = web_driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "\n",
    "Average_salary = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in avg_sal[0:10]:\n",
    "    Average_salary.append(i.text.replace('\\n',''))\n",
    "\n",
    "    \n",
    "#extract the tag having minimum and maximum salary \n",
    "minmax_sal = web_driver.find_elements_by_xpath(\"//span[@class='d-block d-lg-none m-0 css-1b6bxoo']\")\n",
    "\n",
    "Min_Max_salary = [] #empty list\n",
    "#to remove extra data other than output we required\n",
    "for i in minmax_sal[0:10]:\n",
    "    Min_Max_salary.append(i.text.replace('Range: ', ''))\n",
    "\n",
    "    \n",
    "# Make data frame of data science job from glassdoor\n",
    "Glassdoor2 = pd.DataFrame({})\n",
    "Glassdoor2['COMPANY NAME']= company_name\n",
    "Glassdoor2['SALARY NUMBER'] = Salary_Number\n",
    "Glassdoor2['AVERAGE SALARY'] = Average_salary \n",
    "Glassdoor2['MINIMUM MAXIMUM SALARY'] = Min_Max_salary \n",
    "Glassdoor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.6- Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "### 1. Brand\n",
    "### 2. Product Description\n",
    "### 3. Price\n",
    "### 4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.flipkart.com/'\n",
    "web_driver.get(url)\n",
    "#the url will open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect for Job product name field\n",
    "job_search = web_driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "#this will write text on search bar\n",
    "job_search.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "search_button = web_driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=1',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=3']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the tag having urls of all pages\n",
    "url = web_driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']//a\")\n",
    "\n",
    "glasses_urls = [] #empty list\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in url[0:3]:\n",
    "    glasses_urls.append(i.get_attribute('href'))\n",
    "glasses_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND NAME</th>\n",
       "      <th>GLASS DESCRIPTION</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>DISCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wrogn</td>\n",
       "      <td>Mirrored Wayfarer Sunglasses (51)</td>\n",
       "      <td>₹663</td>\n",
       "      <td>73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (53)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹513</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (58)</td>\n",
       "      <td>₹474</td>\n",
       "      <td>68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Sports Sunglasses (73)</td>\n",
       "      <td>₹348</td>\n",
       "      <td>72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection, Mirrored, Gradient Retro Square...</td>\n",
       "      <td>₹246</td>\n",
       "      <td>87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wrogn</td>\n",
       "      <td>Mirrored Wayfarer Sunglasses (52)</td>\n",
       "      <td>₹695</td>\n",
       "      <td>73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized Retro Square Sunglasses (58)</td>\n",
       "      <td>₹474</td>\n",
       "      <td>55%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    BRAND NAME                                  GLASS DESCRIPTION PRICE  \\\n",
       "0        Wrogn                  Mirrored Wayfarer Sunglasses (51)  ₹663   \n",
       "1    ROYAL SON     Polarized, UV Protection Round Sunglasses (53)  ₹664   \n",
       "2    Elligator                UV Protection Round Sunglasses (54)  ₹295   \n",
       "3     Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹513   \n",
       "4     Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹758   \n",
       "..         ...                                                ...   ...   \n",
       "95   ROYAL SON          UV Protection Rectangular Sunglasses (58)  ₹474   \n",
       "96       NuVew               UV Protection Sports Sunglasses (73)  ₹348   \n",
       "97  PHENOMENAL  UV Protection, Mirrored, Gradient Retro Square...  ₹246   \n",
       "98       Wrogn                  Mirrored Wayfarer Sunglasses (52)  ₹695   \n",
       "99   ROYAL SON             Polarized Retro Square Sunglasses (58)  ₹474   \n",
       "\n",
       "   DISCOUNT  \n",
       "0      73%   \n",
       "1      66%   \n",
       "2      88%   \n",
       "3      35%   \n",
       "4      15%   \n",
       "..      ...  \n",
       "95     68%   \n",
       "96     72%   \n",
       "97     87%   \n",
       "98     73%   \n",
       "99     55%   \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brand_name = [] #empty list\n",
    "#extract the tag having brand name\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    brand = web_driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in brand:\n",
    "        Brand_name.append(i.text) #to remove extra data other than output we required\n",
    "Brand_Name = Brand_name[0:100]\n",
    "\n",
    "\n",
    "Description = [] #empty list\n",
    "#extract the tag having description\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    desp = web_driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    for i in desp:\n",
    "        Description.append(i.text) #to remove extra data other than output we required\n",
    "glass_description = Description[0:100]\n",
    "\n",
    "\n",
    "price = [] #empty list\n",
    "#extract the tag having price\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    pri = web_driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for i in pri[0:100]:\n",
    "        price.append(i.text) #to remove extra data other than output we required\n",
    "Price = price[0:100]\n",
    "\n",
    "\n",
    "discount = [] #empty list\n",
    "#extract the tag having discount\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    dis = web_driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    for i in dis[0:100]:\n",
    "        discount.append(i.text.replace('off','')) #to remove extra data other than output we required\n",
    "Discount = discount[0:100]\n",
    "\n",
    "\n",
    "# Make data frame of sunglasses from flipkart.com\n",
    "Sunglasses = pd.DataFrame({})\n",
    "Sunglasses['BRAND NAME']= Brand_Name\n",
    "Sunglasses['GLASS DESCRIPTION'] = glass_description\n",
    "Sunglasses['PRICE'] = Price \n",
    "Sunglasses['DISCOUNT'] = Discount \n",
    "Sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que.7- Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\n",
    "\n",
    "#### 1. Rating \n",
    "#### 2. Review_summary \n",
    "#### 3. Full review\n",
    "### You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = ' https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace'\n",
    "web_driver.get(url)\n",
    "#the url will open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all rewiev button click\n",
    "all_review = web_driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\")\n",
    "all_review.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having urls of all pages\n",
    "url = web_driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']//a\")\n",
    "\n",
    "rev_urls = [] #empty list\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in url[0:10]:\n",
    "    rev_urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating = [] #empty list\n",
    "#extract the tag having rating\n",
    "for i in rev_urls:\n",
    "    web_driver.get(i)\n",
    "    rate = web_driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    for i in rate:\n",
    "        Rating.append(i.text) #to remove extra data other than output we required\n",
    "        \n",
    "        \n",
    "Review_summary = [] #empty list\n",
    "#extract the tag having review summary\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    summary = web_driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    for i in summary:\n",
    "        Review_summary.append(i.text) #to remove extra data other than output we required\n",
    "\n",
    "        \n",
    "Full_review = [] #empty list\n",
    "#extract the tag having Full_review\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    full = web_driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for i in full:\n",
    "        Full_review.append(i.text) #to remove extra data other than output we required\n",
    "\n",
    "\n",
    "# Make data frame of review of i-phone from flipkart.com\n",
    "REVIEWS = pd.DataFrame({})\n",
    "REVIEWS['RATING']= Rating\n",
    "REVIEWS['REVIEW SUMMARY'] = Review_summary\n",
    "REVIEWS['FULL REVIEW'] = Full_review \n",
    "REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brilliant',\n",
       " 'Simply awesome',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Best in the market!',\n",
       " 'Perfect product!',\n",
       " 'Highly recommended',\n",
       " 'Perfect product!',\n",
       " 'Classy product',\n",
       " 'Worth every penny',\n",
       " 'Perfect product!',\n",
       " 'Simply awesome',\n",
       " 'Highly recommended',\n",
       " 'Worth every penny',\n",
       " 'Terrific',\n",
       " 'Nice product',\n",
       " 'Wonderful',\n",
       " 'Classy product',\n",
       " 'Brilliant',\n",
       " 'Must buy!',\n",
       " 'Good choice',\n",
       " 'Perfect product!',\n",
       " 'Wonderful',\n",
       " 'Terrific purchase',\n",
       " 'Great product',\n",
       " 'Simply awesome',\n",
       " 'Mind-blowing purchase',\n",
       " 'Terrific purchase',\n",
       " 'Excellent',\n",
       " 'Simply awesome',\n",
       " 'Good quality product',\n",
       " 'Very poor',\n",
       " 'Perfect product!',\n",
       " 'Must buy!',\n",
       " 'Fabulous!',\n",
       " 'Mind-blowing purchase',\n",
       " 'Mind-blowing purchase',\n",
       " 'Wonderful',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Very Good',\n",
       " 'Perfect product!',\n",
       " 'Classy product',\n",
       " 'Perfect product!',\n",
       " 'Just wow!',\n",
       " 'Awesome',\n",
       " 'Terrific',\n",
       " 'Terrific purchase',\n",
       " 'Awesome',\n",
       " 'Classy product',\n",
       " 'Brilliant',\n",
       " 'Terrific',\n",
       " 'Perfect product!',\n",
       " 'Awesome',\n",
       " 'Perfect product!',\n",
       " 'Very poor',\n",
       " 'Fabulous!',\n",
       " 'Excellent',\n",
       " 'Must buy!',\n",
       " 'Value-for-money',\n",
       " 'Brilliant',\n",
       " 'Terrific purchase',\n",
       " 'Good quality product',\n",
       " 'Perfect product!',\n",
       " 'Awesome',\n",
       " 'Value-for-money',\n",
       " 'Just wow!',\n",
       " 'Super!',\n",
       " 'Best in the market!',\n",
       " 'Classy product',\n",
       " 'Highly recommended',\n",
       " 'Mind-blowing purchase',\n",
       " 'Must buy!',\n",
       " 'Excellent',\n",
       " 'Excellent',\n",
       " 'Terrific',\n",
       " 'Pretty good',\n",
       " 'Nice product',\n",
       " 'Mind-blowing purchase',\n",
       " 'Does the job',\n",
       " 'Wonderful',\n",
       " 'Worth every penny',\n",
       " 'Worth every penny',\n",
       " 'Fabulous!',\n",
       " 'Classy product',\n",
       " 'Awesome',\n",
       " 'Wonderful',\n",
       " 'Terrific purchase',\n",
       " 'Awesome',\n",
       " 'Decent product',\n",
       " 'Super!',\n",
       " 'Fabulous!',\n",
       " 'Just wow!',\n",
       " 'Mind-blowing purchase',\n",
       " 'Excellent']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Review_summary = [] #empty list\n",
    "#extract the tag having review summary\n",
    "for i in glasses_urls:\n",
    "    web_driver.get(i)\n",
    "    summary = web_driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    for i in summary:\n",
    "        Review_summary.append(i.text) #to remove extra data other than output we required\n",
    "Review_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Review_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
